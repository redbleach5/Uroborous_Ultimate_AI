"""
UncertaintySearchMixin - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤–µ–±-–ø–æ–∏—Å–∫ –ø—Ä–∏ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏

–ü–æ–∑–≤–æ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç–∞–º:
1. –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–≤–æ–∏—Ö –æ—Ç–≤–µ—Ç–∞—Ö
2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–∫–∞—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
3. –î–æ–ø–æ–ª–Ω—è—Ç—å –æ—Ç–≤–µ—Ç—ã –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
4. –ü–æ–≤—ã—à–∞—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å–æ —Å–ª–æ–∂–Ω—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞–º–∏
"""

import re
from typing import Dict, Any, Optional, List, Tuple
from ..core.logger import get_logger
from ..llm.base import LLMMessage

logger = get_logger(__name__)


class UncertaintySearchMixin:
    """
    –ú–∏–∫—Å–∏–Ω –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤–µ–±-–ø–æ–∏—Å–∫–∞ –ø—Ä–∏ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏.
    
    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    ```python
    class MyAgent(BaseAgent, UncertaintySearchMixin):
        async def _execute_impl(self, task, context):
            response = await self._get_llm_response(messages)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –ø—Ä–∏ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            enhanced_response = await self.enhance_with_search_if_uncertain(
                response=response,
                task=task,
                context=context
            )
            return enhanced_response
    ```
    """
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã, —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
    UNCERTAINTY_PATTERNS = [
        # –†—É—Å—Å–∫–∏–π
        r"–Ω–µ —É–≤–µ—Ä–µ–Ω",
        r"–Ω–µ –∑–Ω–∞—é —Ç–æ—á–Ω–æ",
        r"–≤–æ–∑–º–æ–∂–Ω–æ",
        r"–≤–µ—Ä–æ—è—Ç–Ω–æ",
        r"–º–æ–∂–µ—Ç –±—ã—Ç—å",
        r"–Ω–µ –º–æ–≥—É —Å–∫–∞–∑–∞—Ç—å",
        r"–º–Ω–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ",
        r"—Ç—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è",
        r"–Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å",
        r"–Ω–µ —Ä–∞—Å–ø–æ–ª–∞–≥–∞—é.*–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π",
        r"–º–æ–∏ –¥–∞–Ω–Ω—ã–µ.*—É—Å—Ç–∞—Ä–µ–ª–∏",
        r"–Ω–µ –∏–º–µ—é.*–¥–æ—Å—Ç—É–ø–∞",
        r"—Ä–µ–∫–æ–º–µ–Ω–¥—É—é.*–ø—Ä–æ–≤–µ—Ä–∏—Ç—å",
        r"—Ç–æ—á–Ω–æ –Ω–µ –º–æ–≥—É",
        r"—Å–ª–æ–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å",
        # English
        r"i'?m not sure",
        r"i don'?t know",
        r"might be",
        r"could be",
        r"possibly",
        r"probably",
        r"uncertain",
        r"need to verify",
        r"my knowledge.*cutoff",
        r"as of my.*training",
    ]
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∑–∞–¥–∞—á, —Ç—Ä–µ–±—É—é—â–∏—Ö –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    REQUIRES_CURRENT_INFO_PATTERNS = [
        r"–ø–æ—Å–ª–µ–¥–Ω(–∏–π|—è—è|–∏–µ|—é—é)",
        r"–∞–∫—Ç—É–∞–ª—å–Ω(—ã–π|–∞—è|—ã–µ|—É—é)",
        r"—Ç–µ–∫—É—â(–∏–π|–∞—è|–∏–µ|—É—é)",
        r"—Å–µ–≥–æ–¥–Ω—è|–≤—á–µ—Ä–∞|–Ω–∞ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ",
        r"–Ω–æ–≤–æ—Å—Ç(–∏|–µ–π|—å)",
        r"—Ä–µ–ª–∏–∑|–≤–µ—Ä—Å–∏—è",
        r"—Ü–µ–Ω(–∞|—ã)|—Å—Ç–æ–∏–º–æ—Å—Ç—å",
        r"–∫—É—Ä—Å|–∫–æ—Ç–∏—Ä–æ–≤–∫–∏",
        r"–ø–æ–≥–æ–¥–∞",
        r"latest|current|today|recent",
        r"price|cost|rate",
        r"version|release",
        r"news|update",
    ]
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã, –≥–¥–µ –≤–∞–∂–Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å
    TECHNICAL_TOPICS_PATTERNS = [
        r"api|sdk|library|framework",
        r"–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è|documentation",
        r"—É—Å—Ç–∞–Ω–æ–≤–∫(–∞|–∏)|install",
        r"–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç(–∏|–µ–π)|dependenc",
        r"–Ω–∞—Å—Ç—Ä–æ–π–∫(–∞|–∏)|config",
        r"–±–∞–≥|bug|issue|–æ—à–∏–±–∫–∞",
        r"—É—è–∑–≤–∏–º–æ—Å—Ç(—å|–∏)|vulnerability|security",
    ]
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∏–∫—Å–∏–Ω–∞"""
        self._uncertainty_threshold = 0.6  # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
        self._search_cache: Dict[str, Any] = {}  # –ö—ç—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
    
    def detect_uncertainty(self, response: str) -> Tuple[bool, float, List[str]]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –æ—Ç–≤–µ—Ç–µ –º–æ–¥–µ–ª–∏.
        
        Args:
            response: –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
            
        Returns:
            (is_uncertain, confidence_score, detected_patterns)
        """
        response_lower = response.lower()
        detected_patterns = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        for pattern in self.UNCERTAINTY_PATTERNS:
            if re.search(pattern, response_lower, re.IGNORECASE):
                detected_patterns.append(pattern)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (—á–µ–º –±–æ–ª—å—à–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ - —Ç–µ–º –º–µ–Ω—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        if detected_patterns:
            # –ö–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω —Å–Ω–∏–∂–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ 15%
            confidence = max(0.1, 1.0 - len(detected_patterns) * 0.15)
        else:
            confidence = 0.95  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        is_uncertain = confidence < self._uncertainty_threshold
        
        if is_uncertain:
            logger.info(
                f"Detected uncertainty in response: confidence={confidence:.2f}, "
                f"patterns={detected_patterns[:3]}"
            )
        
        return is_uncertain, confidence, detected_patterns
    
    def task_requires_current_info(self, task: str) -> Tuple[bool, List[str]]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —Ç—Ä–µ–±—É–µ—Ç –ª–∏ –∑–∞–¥–∞—á–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
        
        Args:
            task: –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
            
        Returns:
            (requires_search, matched_keywords)
        """
        task_lower = task.lower()
        matched = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏
        for pattern in self.REQUIRES_CURRENT_INFO_PATTERNS:
            if re.search(pattern, task_lower, re.IGNORECASE):
                matched.append(pattern)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã
        for pattern in self.TECHNICAL_TOPICS_PATTERNS:
            if re.search(pattern, task_lower, re.IGNORECASE):
                matched.append(pattern)
        
        requires = len(matched) >= 1
        
        if requires:
            logger.info(f"Task requires current info: {matched[:3]}")
        
        return requires, matched
    
    async def search_for_missing_info(
        self, 
        query: str, 
        context: Optional[Dict[str, Any]] = None,
        max_results: int = 5
    ) -> Optional[str]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –≤–µ–±-–ø–æ–∏—Å–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            
        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∏–ª–∏ None
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cache_key = query.lower().strip()[:100]
        if cache_key in self._search_cache:
            logger.debug(f"Using cached search results for: {query[:50]}")
            return self._search_cache[cache_key]
        
        # –ü–æ–ª—É—á–∞–µ–º tool_registry (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É –∞–≥–µ–Ω—Ç–∞)
        tool_registry = getattr(self, 'tool_registry', None)
        if not tool_registry:
            logger.warning("No tool_registry available for web search")
            return None
        
        try:
            logger.info(f"üîç Performing uncertainty-triggered web search: {query[:60]}")
            
            search_result = await tool_registry.execute_tool(
                "web_search",
                {"query": query, "max_results": max_results}
            )
            
            if not search_result.success:
                logger.warning(f"Web search failed: {search_result.error}")
                return None
            
            results = search_result.result.get("results", [])
            if not results:
                logger.info("Web search returned no results")
                return None
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            formatted = "\n\nüì° **–ê–ö–¢–£–ê–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –ò–ù–¢–ï–†–ù–ï–¢–ê:**\n"
            formatted += "=" * 50 + "\n"
            
            for i, result in enumerate(results[:max_results], 1):
                title = result.get('title', '').strip()
                url = result.get('url', '').strip()
                snippet = result.get('snippet', '').strip()
                
                formatted += f"\n**[{i}] {title}**\n"
                if snippet:
                    formatted += f"{snippet}\n"
                formatted += f"üîó {url}\n"
            
            formatted += "\n" + "=" * 50
            formatted += "\n*–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞*\n"
            
            # –ö—ç—à–∏—Ä—É–µ–º
            self._search_cache[cache_key] = formatted
            
            logger.info(f"Web search found {len(results)} results for uncertainty query")
            return formatted
            
        except Exception as e:
            logger.error(f"Error during uncertainty web search: {e}")
            return None
    
    async def enhance_with_search_if_uncertain(
        self,
        response: str,
        task: str,
        context: Optional[Dict[str, Any]] = None,
        force_search: bool = False
    ) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è–µ—Ç –≤–µ–±-–ø–æ–∏—Å–∫–æ–º –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.
        
        Args:
            response: –ò—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
            task: –ó–∞–¥–∞—á–∞
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç
            force_search: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫
            
        Returns:
            {
                "response": str,  # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
                "enhanced": bool,  # –ë—ã–ª –ª–∏ –¥–æ–ø–æ–ª–Ω–µ–Ω
                "confidence": float,  # –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                "search_performed": bool,
                "search_results_count": int
            }
        """
        result = {
            "response": response,
            "enhanced": False,
            "confidence": 0.95,
            "search_performed": False,
            "search_results_count": 0
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        is_uncertain, confidence, patterns = self.detect_uncertainty(response)
        result["confidence"] = confidence
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç—Ä–µ–±—É–µ—Ç –ª–∏ –∑–∞–¥–∞—á–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        requires_current, _ = self.task_requires_current_info(task)
        
        should_search = force_search or is_uncertain or requires_current
        
        if not should_search:
            return result
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        search_query = self._create_search_query(task, response, patterns)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        search_results = await self.search_for_missing_info(search_query, context)
        
        if search_results:
            result["search_performed"] = True
            result["search_results_count"] = search_results.count("[")
            
            # –ü–æ–ª—É—á–∞–µ–º LLM –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞
            llm_manager = getattr(self, 'llm_manager', None)
            if llm_manager:
                enhanced_response = await self._enhance_response_with_search(
                    original_response=response,
                    task=task,
                    search_results=search_results,
                    llm_manager=llm_manager
                )
                if enhanced_response:
                    result["response"] = enhanced_response
                    result["enhanced"] = True
                    logger.info("‚úÖ Response enhanced with web search results")
            else:
                # –ü—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∫ –æ—Ç–≤–µ—Ç—É
                result["response"] = response + "\n\n" + search_results
                result["enhanced"] = True
        
        return result
    
    def _create_search_query(
        self, 
        task: str, 
        response: str, 
        uncertainty_patterns: List[str]
    ) -> str:
        """–°–æ–∑–¥–∞—ë—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"""
        # –ë–µ—Ä—ë–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–¥–∞—á–∏
        # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        stop_words = {
            "–∫–∞–∫", "—á—Ç–æ", "–≥–¥–µ", "–∫–æ–≥–¥–∞", "–ø–æ—á–µ–º—É", "–∫–∞–∫–æ–π", "–∫–∞–∫–∞—è", "–∫–∞–∫–∏–µ",
            "the", "a", "an", "is", "are", "was", "were", "how", "what", "where"
        }
        
        words = task.lower().split()
        keywords = [w for w in words if w not in stop_words and len(w) > 2]
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∑–∞–ø—Ä–æ—Å–∞
        query = " ".join(keywords[:10])
        
        return query
    
    async def _enhance_response_with_search(
        self,
        original_response: str,
        task: str,
        search_results: str,
        llm_manager: Any
    ) -> Optional[str]:
        """–£–ª—É—á—à–∞–µ—Ç –æ—Ç–≤–µ—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        try:
            messages = [
                LLMMessage(
                    role="system",
                    content="""–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—è –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

–ü–†–ê–í–ò–õ–ê:
1. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤–µ–±-–ø–æ–∏—Å–∫–∞ –¥–ª—è –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞
2. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã - —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –µ—Å—Ç—å –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞
3. –£–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (URL) –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤
4. –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å—Ç–∏–ª—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
5. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ"""
                ),
                LLMMessage(
                    role="user",
                    content=f"""–ó–ê–î–ê–ß–ê: {task}

–û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –û–¢–í–ï–¢:
{original_response}

–†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–ï–ë-–ü–û–ò–°–ö–ê:
{search_results}

–£–ª—É—á—à–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç, –¥–æ–±–∞–≤–∏–≤ –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤–µ–±-–ø–æ–∏—Å–∫–∞. 
–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –ø–æ–∏—Å–∫–∞ –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ - –≤–µ—Ä–Ω–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π."""
                )
            ]
            
            response = await llm_manager.generate(
                messages=messages,
                temperature=0.3,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                max_tokens=1500
            )
            
            return response.content
            
        except Exception as e:
            logger.error(f"Error enhancing response: {e}")
            return None
    
    def clear_search_cache(self):
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à –ø–æ–∏—Å–∫–∞"""
        self._search_cache.clear()
        logger.debug("Search cache cleared")

