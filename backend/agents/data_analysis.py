"""
DataAnalysisAgent - Analyzes data and creates ML models

ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ ML Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ.
"""

import re
from typing import Dict, Any, Optional, Tuple
import pandas as pd
import numpy as np
from pathlib import Path
from ..core.logger import get_logger
logger = get_logger(__name__)

from .base import BaseAgent
from ..llm.base import LLMMessage
from ..core.exceptions import AgentException


# ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ ML Ð·Ð°Ð´Ð°Ñ‡
ML_TASK_PATTERNS = {
    "classification": [
        r"ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ðº\w*", r"classify", r"classification",
        r"predict.*class", r"ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€\w*", r"categoriz\w*",
        r"detect\w*", r"Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²\w*", r"Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»\w*.*Ñ‚Ð¸Ð¿"
    ],
    "regression": [
        r"Ñ€ÐµÐ³Ñ€ÐµÑÑ\w*", r"regression", r"predict.*value",
        r"predict.*price", r"Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·\w*", r"forecast\w*",
        r"Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·\w*.*Ñ†ÐµÐ½", r"Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·\w*.*Ð·Ð½Ð°Ñ‡ÐµÐ½"
    ],
    "clustering": [
        r"ÐºÐ»Ð°ÑÑ‚ÐµÑ€\w*", r"cluster\w*", r"segment\w*",
        r"Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€\w*", r"group\w*.*similar"
    ],
    "time_series": [
        r"time.?series", r"Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½\w*.*Ñ€ÑÐ´\w*",
        r"Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·\w*.*Ð²Ñ€ÐµÐ¼ÐµÐ½", r"forecast.*time"
    ]
}

# ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ…
DATA_FILE_PATTERNS = [
    r"['\"]([^'\"]+\.csv)['\"]",
    r"['\"]([^'\"]+\.xlsx)['\"]",
    r"['\"]([^'\"]+\.parquet)['\"]",
    r"Ñ„Ð°Ð¹Ð»[Ð°-Ñ]*\s+([^\s]+\.(?:csv|xlsx|parquet))",
    r"data[^\s]*\.(?:csv|xlsx|parquet)",
]


class DataAnalysisAgent(BaseAgent):
    """
    Agent for data analysis and machine learning.
    
    ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸:
    - ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ñ‚Ð¸Ð¿ ML Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°
    - ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿ÑƒÑ‚Ð¸ Ðº Ñ„Ð°Ð¹Ð»Ð°Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ…
    - Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ AutoML Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
    - Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ñ‚Ñ‡ÐµÑ‚Ñ‹ Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸
    """
    
    def _detect_ml_task_type(self, text: str) -> Tuple[Optional[str], float]:
        """
        ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ñ‚Ð¸Ð¿ ML Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°.
        
        Returns:
            (task_type, confidence) - Ñ‚Ð¸Ð¿ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ
        """
        text_lower = text.lower()
        
        scores = {}
        for task_type, patterns in ML_TASK_PATTERNS.items():
            score = 0
            for pattern in patterns:
                matches = len(re.findall(pattern, text_lower))
                score += matches
            if score > 0:
                scores[task_type] = score
        
        if not scores:
            return None, 0.0
        
        best_type = max(scores, key=scores.get)
        # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ confidence (Ð¼Ð°ÐºÑ 1.0 Ð¿Ñ€Ð¸ 3+ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸ÑÑ…)
        confidence = min(scores[best_type] / 3.0, 1.0)
        
        return best_type, confidence
    
    def _extract_data_path(self, text: str, context: Dict[str, Any]) -> Optional[str]:
        """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° Ð¸Ð»Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°."""
        # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚
        if "data_path" in context:
            return context["data_path"]
        
        # Ð˜Ñ‰ÐµÐ¼ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ
        for pattern in DATA_FILE_PATTERNS:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                path = match.group(1) if match.groups() else match.group(0)
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð°
                if Path(path).exists():
                    return path
        
        return None
    
    def _extract_target_column(self, text: str, context: Dict[str, Any]) -> Optional[str]:
        """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ñ†ÐµÐ»ÐµÐ²ÑƒÑŽ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° Ð¸Ð»Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°."""
        if "target_column" in context:
            return context["target_column"]
        
        # ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ target
        target_patterns = [
            r"target[:\s]+['\"]?(\w+)['\"]?",
            r"predict[:\s]+['\"]?(\w+)['\"]?",
            r"Ñ†ÐµÐ»ÐµÐ²\w*[:\s]+['\"]?(\w+)['\"]?",
            r"Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·\w*[:\s]+['\"]?(\w+)['\"]?",
            r"ÐºÐ¾Ð»Ð¾Ð½Ðº[Ð°Ð¸]\s+['\"]?(\w+)['\"]?",
        ]
        
        for pattern in target_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1)
        
        return None
    
    async def _execute_impl(self, task: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute data analysis task with automatic ML task detection.
        
        Args:
            task: Analysis task description
            context: Additional context (data path, columns, etc.)
            
        Returns:
            Analysis results with optional AutoML training
        """
        logger.info(f"DataAnalysisAgent executing task: {task}")
        
        # ÐÐ²Ñ‚Ð¾Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ‚Ð¸Ð¿Ð° ML Ð·Ð°Ð´Ð°Ñ‡Ð¸
        detected_task_type, confidence = self._detect_ml_task_type(task)
        if detected_task_type and confidence >= 0.5:
            logger.info(f"Detected ML task type: {detected_task_type} (confidence: {confidence:.2f})")
            if "task_type" not in context:
                context["task_type"] = detected_task_type
        
        # ÐÐ²Ñ‚Ð¾Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿ÑƒÑ‚Ð¸ Ðº Ð´Ð°Ð½Ð½Ñ‹Ð¼
        data_path = self._extract_data_path(task, context)
        if data_path:
            context["data_path"] = data_path
            logger.info(f"Detected data path: {data_path}")
        
        # ÐÐ²Ñ‚Ð¾Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ†ÐµÐ»ÐµÐ²Ð¾Ð¹ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸
        target_column = self._extract_target_column(task, context)
        if target_column:
            context["target_column"] = target_column
            logger.info(f"Detected target column: {target_column}")
        
        # Get context
        context_text = await self._get_context(task)
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼, Ð½ÑƒÐ¶Ð½Ð¾ Ð»Ð¸ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð·Ð°Ð¿ÑƒÑÐºÐ°Ñ‚ÑŒ AutoML
        auto_train = (
            detected_task_type in ["classification", "regression"] and
            confidence >= 0.6 and
            "data_path" in context and
            "target_column" in context
        )
        
        system_prompt = """You are an expert data scientist and machine learning engineer. Your task is to analyze data, create models, and provide insights.

Capabilities:
- Exploratory Data Analysis (EDA)
- Statistical analysis
- Feature engineering
- Model selection and training
- Model evaluation
- Visualization recommendations
- Time series analysis
- Clustering and classification

Provide detailed analysis with code examples and recommendations."""
        
        user_prompt = f"""Data Analysis Task: {task}

"""
        
        if context_text:
            user_prompt += f"Relevant context:\n{context_text}\n\n"
        
        if context:
            if "data_path" in context:
                user_prompt += f"Data file path: {context['data_path']}\n"
            if "columns" in context:
                user_prompt += f"Columns: {', '.join(context['columns'])}\n"
            if "target_column" in context:
                user_prompt += f"Target column: {context['target_column']}\n"
            if "task_type" in context:
                user_prompt += f"Task type: {context['task_type']} (classification/regression/clustering)\n"
        
        # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¾ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ð¸ AutoML
        if auto_train:
            user_prompt += "\n\nðŸ¤– AutoML training will be automatically executed for this task."
        elif self.automl_engine and "data_path" in context:
            user_prompt += "\n\nNote: AutoML training is available. Specify target_column to enable."
        
        user_prompt += "\nPlease provide a comprehensive analysis with code and recommendations."
        
        messages = [
            LLMMessage(role="system", content=system_prompt),
            LLMMessage(role="user", content=user_prompt)
        ]
        
        try:
            analysis = await self._get_llm_response(messages)
            
            result = {
                "agent": self.name,
                "task": task,
                "analysis": analysis,
                "success": True,
                "detected_task_type": detected_task_type,
                "detection_confidence": confidence
            }
            
            # ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¸Ð»Ð¸ ÑÐ²Ð½Ñ‹Ð¹ Ð·Ð°Ð¿ÑƒÑÐº AutoML
            should_train = auto_train or ("data_path" in context and "target_column" in context)
            
            if should_train:
                automl_engine = await self._get_automl_engine()
                if automl_engine:
                    try:
                        logger.info(f"Starting AutoML training: {context.get('task_type', 'auto')}")
                        automl_result = await automl_engine.auto_train(
                            data_path=context["data_path"],
                            target_column=context["target_column"],
                            task_type=context.get("task_type", "auto")
                        )
                        result["automl_result"] = automl_result
                        result["automl_auto_triggered"] = auto_train
                        
                        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ°Ð¼Ð¼Ð°Ñ€Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
                        if automl_result.get("success") and automl_result.get("best_model"):
                            best = automl_result["best_model"]
                            result["summary"] = (
                                f"âœ… AutoML completed! Best model: {best.get('name', 'Unknown')} "
                                f"with score {best.get('score', 0):.4f}"
                            )
                    except Exception as e:
                        logger.warning(f"AutoML training failed: {e}")
                        result["automl_error"] = str(e)
            
            # Save to memory
            if self.memory:
                await self.memory.save_solution(
                    task=task,
                    solution=analysis,
                    agent=self.name,
                    metadata={
                        **context,
                        "detected_task_type": detected_task_type,
                        "automl_triggered": should_train
                    }
                )
            
            return result
            
        except Exception as e:
            logger.error(f"DataAnalysisAgent error: {e}")
            raise AgentException(f"Data analysis failed: {e}") from e
    
    async def perform_eda(self, data_path: str) -> Dict[str, Any]:
        """
        Perform Exploratory Data Analysis
        
        Args:
            data_path: Path to data file
            
        Returns:
            EDA results
        """
        try:
            # Load data
            if data_path.endswith('.csv'):
                df = pd.read_csv(data_path)
            elif data_path.endswith('.xlsx'):
                df = pd.read_excel(data_path)
            else:
                raise ValueError(f"Unsupported file format: {data_path}")
            
            # Basic statistics
            stats = {
                "shape": df.shape,
                "columns": df.columns.tolist(),
                "dtypes": df.dtypes.to_dict(),
                "missing_values": df.isnull().sum().to_dict(),
                "numeric_summary": df.describe().to_dict() if len(df.select_dtypes(include=[np.number]).columns) > 0 else {},
                "categorical_summary": {}
            }
            
            # Categorical columns
            cat_cols = df.select_dtypes(include=['object']).columns
            for col in cat_cols:
                stats["categorical_summary"][col] = df[col].value_counts().to_dict()
            
            return {
                "success": True,
                "statistics": stats,
                "recommendations": self._generate_eda_recommendations(stats)
            }
        except Exception as e:
            logger.error(f"EDA error: {e}")
            return {"success": False, "error": str(e)}
    
    def _generate_eda_recommendations(self, stats: Dict[str, Any]) -> list:
        """Generate recommendations based on EDA"""
        recommendations = []
        
        # Check for missing values
        missing = stats.get("missing_values", {})
        if any(v > 0 for v in missing.values()):
            recommendations.append("Consider handling missing values (imputation or removal)")
        
        # Check data types
        if stats.get("shape", [0, 0])[0] < 100:
            recommendations.append("Small dataset - consider data augmentation or collecting more data")
        
        return recommendations

